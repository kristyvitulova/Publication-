"""
Einstein Telescope Autoencoder Training Script
Author: Kristyna Vitulova

Description:
    This script trains a deep convolutional autoencoder on preprocessed 
    Einstein Telescope (ET) noise data. The model is designed to reconstruct
    clean noise-only input and will later be used for anomaly detection 
    by identifying deviations from the learned noise distribution.

Dependencies:
    - torch
    - matplotlib

Input:
    Preprocessed waveform or spectrogram batches, loaded via `train_loader` and `val_loader`.
    Each input tensor should have shape [batch_size, 1, height, width].

Output:
    - Trained model saved in .pth format
    - PDF figure showing training and validation loss curves

Training Procedure:
    1. Forward pass through autoencoder with dropout and batch norm
    2. Minimize MSE reconstruction loss using Adam optimizer
    3. Use ReduceLROnPlateau scheduler to adapt learning rate
    4. Track and visualize training/validation losses over time
"""

import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# === Model Definition ===
class DeeperAutoencoderWithRegularization(nn.Module):
    def __init__(self):
        super().__init__()
        d = 0.07915602034842056  # dropout rate from tuning

        # Encoder
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.drop1 = nn.Dropout(d)
        self.pool1 = nn.MaxPool2d(2, stride=2, return_indices=True)

        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.drop2 = nn.Dropout(d)
        self.pool2 = nn.MaxPool2d(2, stride=2, return_indices=True)

        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        self.drop3 = nn.Dropout(d)
        self.pool3 = nn.MaxPool2d(2, stride=2, return_indices=True)

        # Decoder
        self.unpool1 = nn.MaxUnpool2d(2, stride=2)
        self.deconv1 = nn.ConvTranspose2d(128, 64, 3, padding=1)
        self.bn4 = nn.BatchNorm2d(64)
        self.drop4 = nn.Dropout(d)

        self.unpool2 = nn.MaxUnpool2d(2, stride=2)
        self.deconv2 = nn.ConvTranspose2d(64, 32, 3, padding=1)
        self.bn5 = nn.BatchNorm2d(32)
        self.drop5 = nn.Dropout(d)

        self.unpool3 = nn.MaxUnpool2d(2, stride=2)
        self.deconv3 = nn.ConvTranspose2d(32, 1, 3, padding=1)

    def forward(self, x):
        orig = x.size()
        x = self.conv1(x); x = self.bn1(x); x = self.drop1(x); x, i1 = self.pool1(x); s1 = x.size()
        x = self.conv2(x); x = self.bn2(x); x = self.drop2(x); x, i2 = self.pool2(x); s2 = x.size()
        x = self.conv3(x); x = self.bn3(x); x = self.drop3(x); x, i3 = self.pool3(x); s3 = x.size()
        x = self.unpool1(x, i3, output_size=s2); x = self.deconv1(x); x = self.bn4(x); x = self.drop4(x)
        x = self.unpool2(x, i2, output_size=s1); x = self.deconv2(x); x = self.bn5(x); x = self.drop5(x)
        x = self.unpool3(x, i1, output_size=orig); x = self.deconv3(x)
        return x

# === Configuration ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DeeperAutoencoderWithRegularization().to(device)

# Optimizer and scheduler
optimizer = optim.Adam(
    model.parameters(),
    lr=4.741390686132914e-05,
    weight_decay=2.9103837006459895e-06
)
criterion = nn.MSELoss()
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)

# Training parameters
num_epochs = 65
train_losses, val_losses = [], []

# === Training Loop ===
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    for batch in train_loader:
        x = batch[0].to(device)
        optimizer.zero_grad()
        y = model(x)
        loss = criterion(y, x)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    train_losses.append(train_loss / len(train_loader))

    # Validation
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for batch in val_loader:
            x = batch[0].to(device)
            y = model(x)
            loss = criterion(y, x)
            val_loss += loss.item()
    val_losses.append(val_loss / len(val_loader))
    scheduler.step(val_losses[-1])

    print(f"[{epoch+1}/{num_epochs}] Train Loss: {train_losses[-1]:.6f}, Val Loss: {val_losses[-1]:.6f}")

# === Save Trained Model ===
# Replace with your desired output path for saving model weights
model_path = "autoencoder_ET.pth" 
torch.save(model.state_dict(), model_path)
print(f"Model saved to '{model_path}'.")

# === Visualization ===
# Loss curve will be saved in the working directory (or modify path as needed)
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training and Validation Loss")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("train_val_loss_curve.pdf")  # <-- Replace path if needed
plt.show()
